# wrk тестирование 3 реплик

Тестируем 3 реплики, в скриптах установил параметры from и ack равные 3, чтобы учитывать и ожидание ответов от всех реплик.
И PUT и GET запросами выдерживается уже только около 30000 rps:
```
./put.sh 60 30000

Running 1m test @ http://localhost:12345
  6 threads and 64 connections
  Thread calibration: mean lat.: 11.979ms, rate sampling interval: 24ms
  Thread calibration: mean lat.: 10.738ms, rate sampling interval: 19ms
  Thread calibration: mean lat.: 13.134ms, rate sampling interval: 20ms
  Thread calibration: mean lat.: 8.341ms, rate sampling interval: 16ms
  Thread calibration: mean lat.: 7.640ms, rate sampling interval: 21ms
  Thread calibration: mean lat.: 11.218ms, rate sampling interval: 21ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    16.46ms   65.42ms 782.85ms   95.27%
    Req/Sec     5.13k   620.14     8.13k    79.02%
  1799083 requests in 1.00m, 114.95MB read
Requests/sec:  29985.49
Transfer/sec:      1.92MB
```
И GET:
```
./get.sh 60 30000

Running 1m test @ http://localhost:12345
  6 threads and 64 connections
  Thread calibration: mean lat.: 671.389ms, rate sampling interval: 3227ms
  Thread calibration: mean lat.: 808.521ms, rate sampling interval: 4067ms
  Thread calibration: mean lat.: 634.616ms, rate sampling interval: 2717ms
  Thread calibration: mean lat.: 619.641ms, rate sampling interval: 2951ms
  Thread calibration: mean lat.: 485.781ms, rate sampling interval: 2574ms
  Thread calibration: mean lat.: 432.413ms, rate sampling interval: 2347ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.41ms    1.90ms 124.80ms   98.23%
    Req/Sec     5.00k     4.40     5.02k    78.22%
  1799274 requests in 1.00m, 124.78MB read
  Non-2xx or 3xx responses: 661920
Requests/sec:  29988.13
Transfer/sec:      2.08MB
```

Удивительно, что оба видов запросов примерно одинаково отработали - видно теперь сетевые издержки покрыли разницу между ними.
Очень много времени занимает теперь ожидание ответов и агрегация результатов вместе. Так же теперь мы посылали запросы
сразу нескольким репликам, а не одному шарду.

# профилирование 3 реплик

Вcе профили выглядят довольно хорошо. 60% cpu занимает работа базы, что является "основной необходимой" работой.
13,5% send, что тоже необходимая работа.
...Потом я понял, что это был профиль не той реплики, по которой я стрелял из wrk, а другой, потому что у них были
одинаковые Jps имена :) Профили с профилем этой реплики лежат в файлах *...-3-replics-....html*.

Теперь всё-таки интересный профиль мастера. Сразу выделяется область 20% с компилятором. Код мастера, где производится
подсчёт количества пришедших запросов, агрегация разельтата и прочая работа - менее прямолинейный, чем на репликах - видимо,
поэтому такую заметную область компилятор занял. Так и с PUT, и с GET профилями.
А так большую долю снова заняло http взаимодействие с репликами. Там виден 0,5% __read и 5% __writev. Понятно, что у http
заметные накладные расходы. Вероятно, отказавшись от ненужных хедеров, можно было бы уменьшить занимаемое им время.
5,6% Занял ForkJoinThread (треды, создаваемые в sendAsync), в котором только 1,7% __send.
GET и PUT профили особо не отличаются.

Аллокации большая часть тоже за httpClient-ом. В 86,5% ThreadPoolExecutor$Worker есть только 9,45% выполнение запроса сервисом.
Но в нём 7,7% на proxyRequest, который аллоцирует нужные объекты для проксирования запроса реплике. Всего 0,7% отдан базе,
и около процента на объекты для агрегации результатов запросов репликам. А в GET запросах целых 8,2% за базой.

78% локов на http клиенте. Но 20% за levelDB. А в GET запросах больше половины за блокировками в базе.

# Выводы

Видно, что снова очень всё упирается в отправку и обработку запросов через http client.
Теперь запрос может проксироваться не только на одну другую ноду, а на любое количетсво. Но в данном кластере это не сильно влияло,
потому что запросы отправляются более менее параллельно и могут обрабатываться тоже параллельно. А агрегация запросов на
малом кластере съедает крошечную долю ресурсов, всё упирается в сетевое взаимодействие.

Очень хочется переделать хэширование рандеву на консистентное из-за очень неприятного кода, полученного при попытке переделать
алгоритм на возвращение не одной ноды, а нескольких. В рандеву приходится аллоцировать массив размером с количество нод
и сортировать его. На больших кластерах в это можно теоретически упереться. Думал, сделать один массив, и его переиспользовать,
но тогда нельзя будет обращаться из разных процессов к NodeMapper. Пришла в голову идея предаллоцирорвать каждому треду
свой массив... Пока оставил аллокацию массива каждый раз.
